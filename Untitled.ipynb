{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a74a6c6-f460-491a-9f33-eaa0ef8cd769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Setting up data augmentation...\n",
      "Starting self-supervised pretraining...\n",
      "Epoch 1/50, Loss: 2.4413\n",
      "Epoch 2/50, Loss: 2.2131\n",
      "Epoch 3/50, Loss: 2.1813\n",
      "Epoch 4/50, Loss: 2.1443\n",
      "Epoch 5/50, Loss: 2.1240\n",
      "Epoch 6/50, Loss: 2.0516\n",
      "Epoch 7/50, Loss: 2.0532\n",
      "Epoch 8/50, Loss: 2.0435\n",
      "Epoch 9/50, Loss: 2.0527\n",
      "Epoch 10/50, Loss: 2.0554\n",
      "Epoch 11/50, Loss: 2.0440\n",
      "Epoch 12/50, Loss: 2.0320\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1104\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1104\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 1096\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1093\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# Run the full pipeline\u001b[39;00m\n\u001b[0;32m-> 1096\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfull_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResNet Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 758\u001b[0m, in \u001b[0;36mfull_training_pipeline\u001b[0;34m(data_dir, num_classes, device)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# Train with SimCLR\u001b[39;00m\n\u001b[1;32m    757\u001b[0m simclr_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(simclr_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0003\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m--> 758\u001b[0m simclr_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_simclr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimclr_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimclr_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimclr_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# 6. Create models for supervised fine-tuning\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating supervised models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 662\u001b[0m, in \u001b[0;36mtrain_simclr\u001b[0;34m(model, dataloader, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m    661\u001b[0m loss \u001b[38;5;241m=\u001b[39m nt_xent_loss(z1, z2)\n\u001b[0;32m--> 662\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    665\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/jupyter/lib/python3.9/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/jupyter/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.21/envs/jupyter/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "import timm\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "#####################################\n",
    "# 1. Custom Dataset with Augmentations\n",
    "#####################################\n",
    "class SmallDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, return_idx=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.return_idx = return_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.return_idx:\n",
    "            return image, label, idx\n",
    "        return image, label\n",
    "\n",
    "#####################################\n",
    "# 2. Strong Augmentation Pipelines\n",
    "#####################################\n",
    "class RandAugment:\n",
    "    def __init__(self, n=2, m=9):\n",
    "        self.n = n  # Number of augmentation transformations to apply\n",
    "        self.m = m  # Magnitude for all transformations\n",
    "        self.augment_list = [\n",
    "            self.auto_contrast,\n",
    "            self.equalize,\n",
    "            self.rotate,\n",
    "            self.solarize,\n",
    "            self.color,\n",
    "            self.contrast,\n",
    "            self.brightness,\n",
    "            self.sharpness,\n",
    "            self.shear_x,\n",
    "            self.shear_y,\n",
    "            self.translate_x,\n",
    "            self.translate_y,\n",
    "        ]\n",
    "            \n",
    "    def auto_contrast(self, img, magnitude):\n",
    "        return ImageOps.autocontrast(img)\n",
    "    \n",
    "    def equalize(self, img, magnitude):\n",
    "        return ImageOps.equalize(img)\n",
    "    \n",
    "    def rotate(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 30\n",
    "        return img.rotate(magnitude)\n",
    "    \n",
    "    def solarize(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 256\n",
    "        return ImageOps.solarize(img, magnitude)\n",
    "    \n",
    "    def color(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 1.8 + 0.1\n",
    "        return ImageEnhance.Color(img).enhance(magnitude)\n",
    "    \n",
    "    def contrast(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 1.8 + 0.1\n",
    "        return ImageEnhance.Contrast(img).enhance(magnitude)\n",
    "    \n",
    "    def brightness(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 1.8 + 0.1\n",
    "        return ImageEnhance.Brightness(img).enhance(magnitude)\n",
    "    \n",
    "    def sharpness(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 1.8 + 0.1\n",
    "        return ImageEnhance.Sharpness(img).enhance(magnitude)\n",
    "    \n",
    "    def shear_x(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 0.3\n",
    "        return img.transform(img.size, Image.AFFINE, (1, magnitude, 0, 0, 1, 0))\n",
    "    \n",
    "    def shear_y(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * 0.3\n",
    "        return img.transform(img.size, Image.AFFINE, (1, 0, 0, magnitude, 1, 0))\n",
    "    \n",
    "    def translate_x(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * float(img.size[0] / 3)\n",
    "        return img.transform(img.size, Image.AFFINE, (1, 0, magnitude, 0, 1, 0))\n",
    "    \n",
    "    def translate_y(self, img, magnitude):\n",
    "        magnitude = (magnitude / 10) * float(img.size[1] / 3)\n",
    "        return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude))\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        ops = random.choices(self.augment_list, k=self.n)\n",
    "        for op in ops:\n",
    "            img = op(img, self.m)\n",
    "        return img\n",
    "\n",
    "def get_strong_augmentation(img_size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.2),\n",
    "        transforms.RandomApply([transforms.RandomRotation(20)], p=0.5),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2)], p=0.5),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.2),\n",
    "        transforms.RandomPerspective(distortion_scale=0.3, p=0.3),\n",
    "        RandAugment(n=2, m=9),\n",
    "        transforms.RandomApply([transforms.RandomErasing(p=0.3, scale=(0.02, 0.33), ratio=(0.3, 3.3))], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "def get_test_augmentation(img_size=224):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "#####################################\n",
    "# 3. Test-Time Augmentation\n",
    "#####################################\n",
    "class TTAWrapper(nn.Module):\n",
    "    def __init__(self, model, tta_transforms):\n",
    "        super(TTAWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.tta_transforms = tta_transforms\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        \n",
    "        for transform in self.tta_transforms:\n",
    "            transformed_x = torch.stack([transform(img) for img in x])\n",
    "            output = self.model(transformed_x)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        # Average predictions\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        return outputs.mean(dim=0)\n",
    "\n",
    "def get_tta_transforms(img_size=224):\n",
    "    tta_transforms = [\n",
    "        transforms.Compose([\n",
    "            transforms.Lambda(lambda x: x),  # Identity\n",
    "        ]),\n",
    "        transforms.Compose([\n",
    "            transforms.Lambda(lambda x: TF.hflip(x)),\n",
    "        ]),\n",
    "        transforms.Compose([\n",
    "            transforms.Lambda(lambda x: TF.vflip(x)),\n",
    "        ]),\n",
    "        transforms.Compose([\n",
    "            transforms.Lambda(lambda x: TF.rotate(x, 90)),\n",
    "        ]),\n",
    "        transforms.Compose([\n",
    "            transforms.Lambda(lambda x: TF.rotate(x, 180)),\n",
    "        ])\n",
    "    ]\n",
    "    return tta_transforms\n",
    "\n",
    "#####################################\n",
    "# 4. Mixup and CutMix Implementation\n",
    "#####################################\n",
    "def mixup_data(x, y, alpha=0.8):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def cutmix_data(x, y, alpha=0.8):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x_mixed = x.clone()\n",
    "    x_mixed[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    \n",
    "    # Adjust lambda to match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return x_mixed, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # Uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "#####################################\n",
    "# 5. Progressive Layer Unfreezing\n",
    "#####################################\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def unfreeze_layers(model, layer_name):\n",
    "    for name, param in model.named_parameters():\n",
    "        if layer_name in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "def unfreeze_model_stages(model, model_type, stages=None):\n",
    "    \"\"\"\n",
    "    Unfreeze specific stages of ResNet or DeiT\n",
    "    \"\"\"\n",
    "    if stages is None:\n",
    "        # Unfreeze all\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        return\n",
    "    \n",
    "    # First freeze all\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    if model_type == 'resnet':\n",
    "        # ResNet stages\n",
    "        if 'head' in stages:\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "        if 'layer4' in stages:\n",
    "            for param in model.layer4.parameters():\n",
    "                param.requires_grad = True\n",
    "        if 'layer3' in stages:\n",
    "            for param in model.layer3.parameters():\n",
    "                param.requires_grad = True\n",
    "        if 'layer2' in stages:\n",
    "            for param in model.layer2.parameters():\n",
    "                param.requires_grad = True\n",
    "        if 'layer1' in stages:\n",
    "            for param in model.layer1.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    elif model_type == 'deit':\n",
    "        # DeiT stages\n",
    "        if 'head' in stages:\n",
    "            for param in model.head.parameters():\n",
    "                param.requires_grad = True\n",
    "        if 'blocks' in stages:\n",
    "            # Determine which blocks to unfreeze\n",
    "            num_blocks = len(model.blocks)\n",
    "            blocks_to_unfreeze = []\n",
    "            if 'blocks_last_3' in stages:\n",
    "                blocks_to_unfreeze.extend(range(num_blocks-3, num_blocks))\n",
    "            if 'blocks_last_6' in stages:\n",
    "                blocks_to_unfreeze.extend(range(num_blocks-6, num_blocks-3))\n",
    "            if 'blocks_all' in stages:\n",
    "                blocks_to_unfreeze.extend(range(num_blocks))\n",
    "            \n",
    "            # Unfreeze specified blocks\n",
    "            for i in blocks_to_unfreeze:\n",
    "                for param in model.blocks[i].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "#####################################\n",
    "# 6. Knowledge Distillation\n",
    "#####################################\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, base_criterion, teacher_model, distillation_alpha=0.5, distillation_tau=3.0):\n",
    "        super().__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.teacher_model = teacher_model\n",
    "        self.distillation_alpha = distillation_alpha\n",
    "        self.distillation_tau = distillation_tau\n",
    "    \n",
    "    def forward(self, inputs, outputs, targets):\n",
    "        # Compute base loss\n",
    "        base_loss = self.base_criterion(outputs, targets)\n",
    "        \n",
    "        # Compute distillation loss (KL divergence)\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = self.teacher_model(inputs)\n",
    "        \n",
    "        # Compute soft targets\n",
    "        # Apply temperature scaling\n",
    "        T = self.distillation_tau\n",
    "        soft_targets = F.softmax(teacher_outputs / T, dim=-1)\n",
    "        soft_outputs = F.log_softmax(outputs / T, dim=-1)\n",
    "        distillation_loss = F.kl_div(soft_outputs, soft_targets, reduction='batchmean') * (T * T)\n",
    "        \n",
    "        # Combine losses\n",
    "        loss = base_loss * (1 - self.distillation_alpha) + distillation_loss * self.distillation_alpha\n",
    "        return loss\n",
    "\n",
    "#####################################\n",
    "# 7. Create Models with Modifications\n",
    "#####################################\n",
    "def create_resnet_model(num_classes, model_type='resnet18', pretrained=True, feature_extract=True):\n",
    "    if model_type == 'resnet18':\n",
    "        model = resnet18(pretrained=pretrained)\n",
    "    elif model_type == 'resnet34':\n",
    "        model = resnet34(pretrained=pretrained)\n",
    "    elif model_type == 'resnet50':\n",
    "        model = resnet50(pretrained=pretrained)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "    \n",
    "    # Freeze all layers if feature extracting\n",
    "    if feature_extract:\n",
    "        set_parameter_requires_grad(model, feature_extracting=True)\n",
    "    \n",
    "    # Modify the final fully connected layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_deit_model(num_classes, model_type='deit_tiny_patch16_224', pretrained=True, feature_extract=True):\n",
    "    model = timm.create_model(model_type, pretrained=pretrained)\n",
    "    \n",
    "    # Freeze all layers if feature extracting\n",
    "    if feature_extract:\n",
    "        set_parameter_requires_grad(model, feature_extracting=True)\n",
    "    \n",
    "    # Modify the head\n",
    "    num_ftrs = model.head.in_features\n",
    "    model.head = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_ftrs, num_classes)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "#####################################\n",
    "# 8. Cross-Validation Implementation\n",
    "#####################################\n",
    "def k_fold_cross_validation(dataset, model_fn, num_classes, k=5, batch_size=32, num_epochs=100, learning_rate=0.001, \n",
    "                           weight_decay=0.01, device='cuda', model_type='resnet'):\n",
    "    \n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    \n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(indices)):\n",
    "        print(f\"Fold {fold+1}/{k}\")\n",
    "        \n",
    "        # Create data samplers\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        val_sampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "        \n",
    "        # Create the model\n",
    "        model = model_fn(num_classes=num_classes)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create optimizer and scheduler\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
    "        \n",
    "        # Train the model\n",
    "        best_acc = 0.0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Progressive unfreezing\n",
    "            if epoch == 0:\n",
    "                if model_type == 'resnet':\n",
    "                    unfreeze_model_stages(model, 'resnet', ['head'])\n",
    "                else:\n",
    "                    unfreeze_model_stages(model, 'deit', ['head'])\n",
    "            elif epoch == 20:\n",
    "                if model_type == 'resnet':\n",
    "                    unfreeze_model_stages(model, 'resnet', ['head', 'layer4'])\n",
    "                else:\n",
    "                    unfreeze_model_stages(model, 'deit', ['head', 'blocks_last_3'])\n",
    "            elif epoch == 40:\n",
    "                if model_type == 'resnet':\n",
    "                    unfreeze_model_stages(model, 'resnet', ['head', 'layer4', 'layer3'])\n",
    "                else:\n",
    "                    unfreeze_model_stages(model, 'deit', ['head', 'blocks_last_3', 'blocks_last_6'])\n",
    "            \n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Apply mixup or cutmix\n",
    "                if random.random() < 0.5:\n",
    "                    inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=0.8)\n",
    "                elif random.random() < 0.5:\n",
    "                    inputs, labels_a, labels_b, lam = cutmix_data(inputs, labels, alpha=0.8)\n",
    "                else:\n",
    "                    labels_a, labels_b, lam = labels, labels, 1.0\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    if lam != 1.0:\n",
    "                        loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                    else:\n",
    "                        loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_acc = correct / total\n",
    "            print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {epoch_acc:.4f}\")\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # Save best model\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        fold_results.append(best_acc)\n",
    "        print(f\"Fold {fold+1} best accuracy: {best_acc:.4f}\")\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save(best_model_state, f\"model_fold_{fold+1}.pth\")\n",
    "    \n",
    "    # Print overall results\n",
    "    print(f\"K-fold cross-validation results: {fold_results}\")\n",
    "    print(f\"Average accuracy: {sum(fold_results)/len(fold_results):.4f}\")\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "#####################################\n",
    "# 9. Semi-Supervised Learning (Pseudo-Labeling)\n",
    "#####################################\n",
    "def pseudo_labeling(labeled_dataset, unlabeled_paths, model, device, confidence_threshold=0.85):\n",
    "    model.eval()\n",
    "    transform = get_test_augmentation()\n",
    "    pseudo_labeled_data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_path in unlabeled_paths:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "            outputs = model(img_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            if confidence.item() > confidence_threshold:\n",
    "                pseudo_labeled_data.append((img_path, predicted.item()))\n",
    "    \n",
    "    # Create new dataset with both labeled and pseudo-labeled data\n",
    "    all_paths = [p for p, _ in labeled_dataset.image_paths] + [p for p, _ in pseudo_labeled_data]\n",
    "    all_labels = labeled_dataset.labels + [l for _, l in pseudo_labeled_data]\n",
    "    \n",
    "    return all_paths, all_labels\n",
    "\n",
    "#####################################\n",
    "# 10. Self-Supervised Learning with SimCLR\n",
    "#####################################\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_features),\n",
    "            nn.BatchNorm1d(hidden_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, backbone, projection_dim=128):\n",
    "        super(SimCLR, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone.fc = nn.Identity()  # Remove classifier\n",
    "        \n",
    "        # Add projection head\n",
    "        self.projection_head = ProjectionHead(\n",
    "            in_features=self.backbone.inplanes,\n",
    "            hidden_features=self.backbone.inplanes,\n",
    "            out_features=projection_dim\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        projections = self.projection_head(features)\n",
    "        return projections\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Normalized Temperature-scaled Cross Entropy Loss from SimCLR paper\n",
    "    \"\"\"\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    batch_size = z1.shape[0]\n",
    "    representations = torch.cat([z1, z2], dim=0)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "    \n",
    "    # Create masks for positive pairs\n",
    "    sim_i_j = torch.diag(similarity_matrix, batch_size)\n",
    "    sim_j_i = torch.diag(similarity_matrix, -batch_size)\n",
    "    \n",
    "    # We need to remove the diagonal elements from the similarity matrix \n",
    "    # to get only negative samples\n",
    "    mask = torch.ones_like(similarity_matrix) - torch.eye(2 * batch_size, device=z1.device)\n",
    "    \n",
    "    # Filter out the positives from the negative samples\n",
    "    pos_mask = torch.zeros(2 * batch_size, 2 * batch_size, device=z1.device)\n",
    "    pos_mask[:batch_size, batch_size:] = torch.eye(batch_size, device=z1.device)\n",
    "    pos_mask[batch_size:, :batch_size] = torch.eye(batch_size, device=z1.device)\n",
    "    mask = mask * (1 - pos_mask)\n",
    "    \n",
    "    # Get negative samples\n",
    "    neg_sim = similarity_matrix * mask\n",
    "    \n",
    "    # For numerical stability\n",
    "    neg_sim = neg_sim.view(2 * batch_size, -1)\n",
    "    \n",
    "    # Positive pairs\n",
    "    pos_sim = torch.cat([sim_i_j.unsqueeze(1), sim_j_i.unsqueeze(1)], dim=0)\n",
    "    \n",
    "    # Logits: [2*batch_size, 1+2*batch_size-2]\n",
    "    logits = torch.cat([pos_sim, neg_sim], dim=1) / temperature\n",
    "    \n",
    "    # Labels: positives are the first column\n",
    "    labels = torch.zeros(2 * batch_size, dtype=torch.long, device=z1.device)\n",
    "    \n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def simclr_transform(img_size=224):\n",
    "    \"\"\"\n",
    "    SimCLR augmentation pipeline\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.2, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0))], p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class TwoCropTransform:\n",
    "    \"\"\"\n",
    "    Create two crops of the same image\n",
    "    \"\"\"\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return [self.transform(x), self.transform(x)]\n",
    "\n",
    "def train_simclr(model, dataloader, optimizer, device, epochs=100):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, _ in dataloader:\n",
    "            # Get the two views\n",
    "            img1 = images[0].to(device)\n",
    "            img2 = images[1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            z1 = model(img1)\n",
    "            z2 = model(img2)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = nt_xent_loss(z1, z2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_image_dataset(data_directory):\n",
    "    \"\"\"\n",
    "    Load images and labels from a directory structure where:\n",
    "    data/\n",
    "    ├── Class1/\n",
    "    │   ├── image1.jpg\n",
    "    │   └── image2.jpg\n",
    "    └── Class2/\n",
    "        └── image3.jpg\n",
    "    \n",
    "    Returns:\n",
    "    - image_paths: List of paths to all images\n",
    "    - labels: List of corresponding labels for each image\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get the absolute path to ensure consistent behavior\n",
    "    data_dir = Path(data_directory)\n",
    "    \n",
    "    # Supported image extensions\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']\n",
    "    \n",
    "    # Walk through the data directory\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = data_dir / class_name\n",
    "        \n",
    "        # Skip if not a directory\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        # Process all image files in the class directory\n",
    "        for file_name in os.listdir(class_dir):\n",
    "            file_path = class_dir / file_name\n",
    "            \n",
    "            # Check if it's a valid image file\n",
    "            if file_path.is_file() and file_path.suffix.lower() in image_extensions:\n",
    "                # Add the image path and its label\n",
    "                image_paths.append(str(file_path))\n",
    "                labels.append(class_name)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "#####################################\n",
    "# 11. Full Training Pipeline - Main Functions\n",
    "#####################################\n",
    "def full_training_pipeline(data_dir, num_classes, device='cuda'):\n",
    "    # 1. Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    # Implement your data loading logic here to get image_paths and labels\n",
    "    # For this example:\n",
    "    # image_pathss = [os.path.join(data_dir, f) for f in os.listdir(data_dir) ]\n",
    "    # # Assuming equal distribution of classes for demonstration\n",
    "    # labelss = [i % num_classes for i in range(len(image_pathss))]\n",
    "    # print(image_pathss)\n",
    "    image_paths, labels = load_image_dataset(\"./data\")\n",
    "    \n",
    "    # 2. Data augmentation\n",
    "    print(\"Setting up data augmentation...\")\n",
    "    train_transform = get_strong_augmentation()\n",
    "    val_transform = get_test_augmentation()\n",
    "    \n",
    "    # 3. Split data into train and validation\n",
    "    train_size = int(0.8 * len(image_paths))\n",
    "    val_size = len(image_paths) - train_size\n",
    "    \n",
    "    train_dataset = SmallDataset(image_paths[:train_size], labels[:train_size], transform=train_transform)\n",
    "    val_dataset = SmallDataset(image_paths[train_size:], labels[train_size:], transform=val_transform)\n",
    "    \n",
    "    # 4. Set up dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # 5. Optional: Self-supervised pretraining with SimCLR\n",
    "    print(\"Starting self-supervised pretraining...\")\n",
    "    \n",
    "    # Create base model for SimCLR\n",
    "    base_model = resnet18(pretrained=True)\n",
    "    simclr_model = SimCLR(backbone=base_model).to(device)\n",
    "    \n",
    "    # Create SimCLR dataset with two-crop transform\n",
    "    simclr_transforms = TwoCropTransform(simclr_transform())\n",
    "    simclr_dataset = SmallDataset(image_paths, labels, transform=simclr_transforms)\n",
    "    simclr_loader = DataLoader(simclr_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "    \n",
    "    # Train with SimCLR\n",
    "    simclr_optimizer = optim.AdamW(simclr_model.parameters(), lr=0.0003, weight_decay=0.1)\n",
    "    simclr_model = train_simclr(simclr_model, simclr_loader, simclr_optimizer, device, epochs=50)\n",
    "    \n",
    "    # 6. Create models for supervised fine-tuning\n",
    "    print(\"Creating supervised models...\")\n",
    "    \n",
    "    # Create ResNet model (using pretrained weights from SimCLR)\n",
    "    resnet_model = create_resnet_model(num_classes, model_type='resnet18', pretrained=True, feature_extract=True)\n",
    "    # Load SimCLR backbone weights\n",
    "    state_dict = simclr_model.backbone.state_dict()\n",
    "    resnet_model.load_state_dict(state_dict, strict=False)\n",
    "    resnet_model = resnet_model.to(device)\n",
    "    \n",
    "    # Create DeiT model\n",
    "    deit_model = create_deit_model(num_classes, model_type='deit_tiny_patch16_224', pretrained=True, feature_extract=True)\n",
    "    deit_model = deit_model.to(device)\n",
    "    \n",
    "    # 7. Create teacher model for knowledge distillation\n",
    "    teacher_model = resnet50(pretrained=True)\n",
    "    num_ftrs = teacher_model.fc.in_features\n",
    "    teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    teacher_model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    # 8. Set up optimizers with lower learning rates\n",
    "    resnet_optimizer = optim.AdamW(resnet_model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "    deit_optimizer = optim.AdamW(deit_model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "    \n",
    "    # 9. Set up learning rate schedulers\n",
    "    resnet_scheduler = CosineAnnealingLR(resnet_optimizer, T_max=100)\n",
    "    deit_scheduler = CosineAnnealingLR(deit_optimizer, T_max=100)\n",
    "    \n",
    "    # 10. Set up loss functions with label smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.2)\n",
    "    \n",
    "    # Distillation loss for the DeiT model\n",
    "    distillation_loss = DistillationLoss(\n",
    "        base_criterion=criterion,\n",
    "        teacher_model=teacher_model,\n",
    "        distillation_alpha=0.5,\n",
    "        distillation_tau=3.0\n",
    "    )\n",
    "    \n",
    "    # 11. Set up gradient scaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 12. Training loops for both models\n",
    "    best_resnet_acc = 0.0\n",
    "    best_deit_acc = 0.0\n",
    "    best_resnet_model = None\n",
    "    best_deit_model = None\n",
    "    patience = 20\n",
    "    resnet_patience_counter = 0\n",
    "    deit_patience_counter = 0\n",
    "    \n",
    "    print(\"Starting ResNet training...\")\n",
    "    # ResNet training loop\n",
    "    for epoch in range(100):  # 100 epochs\n",
    "        # Progressive unfreezing for ResNet\n",
    "        if epoch == 0:\n",
    "            unfreeze_model_stages(resnet_model, 'resnet', ['head'])\n",
    "        elif epoch == 20:\n",
    "            unfreeze_model_stages(resnet_model, 'resnet', ['head', 'layer4'])\n",
    "        elif epoch == 40:\n",
    "            unfreeze_model_stages(resnet_model, 'resnet', ['head', 'layer4', 'layer3'])\n",
    "        elif epoch == 60:\n",
    "            unfreeze_model_stages(resnet_model, 'resnet', ['head', 'layer4', 'layer3', 'layer2'])\n",
    "        \n",
    "        # Training phase\n",
    "        resnet_model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply mixup or cutmix with high probability\n",
    "            r = random.random()\n",
    "            if r < 0.4:  # 40% chance of mixup\n",
    "                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=0.8)\n",
    "            elif r < 0.8:  # 40% chance of cutmix\n",
    "                inputs, labels_a, labels_b, lam = cutmix_data(inputs, labels, alpha=0.8)\n",
    "            else:  # 20% no augmentation\n",
    "                labels_a, labels_b, lam = labels, labels, 1.0\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            resnet_optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = resnet_model(inputs)\n",
    "                if lam != 1.0:\n",
    "                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(resnet_optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate epoch loss\n",
    "        epoch_loss = train_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        resnet_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = resnet_model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Epoch {epoch+1}/100, ResNet Loss: {epoch_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        resnet_scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_resnet_acc:\n",
    "            best_resnet_acc = val_acc\n",
    "            best_resnet_model = resnet_model.state_dict().copy()\n",
    "            resnet_patience_counter = 0\n",
    "        else:\n",
    "            resnet_patience_counter += 1\n",
    "            if resnet_patience_counter >= patience:\n",
    "                print(f\"Early stopping ResNet training at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"Best ResNet validation accuracy: {best_resnet_acc:.4f}\")\n",
    "    \n",
    "    # Save the best ResNet model\n",
    "    torch.save(best_resnet_model, \"best_resnet_model.pth\")\n",
    "    \n",
    "    print(\"Starting DeiT training...\")\n",
    "    # DeiT training loop\n",
    "    for epoch in range(100):  # 100 epochs\n",
    "        # Progressive unfreezing for DeiT\n",
    "        if epoch == 0:\n",
    "            unfreeze_model_stages(deit_model, 'deit', ['head'])\n",
    "        elif epoch == 20:\n",
    "            unfreeze_model_stages(deit_model, 'deit', ['head', 'blocks_last_3'])\n",
    "        elif epoch == 40:\n",
    "            unfreeze_model_stages(deit_model, 'deit', ['head', 'blocks_last_3', 'blocks_last_6'])\n",
    "        \n",
    "        # Training phase\n",
    "        deit_model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Apply mixup or cutmix with high probability\n",
    "            r = random.random()\n",
    "            if r < 0.4:  # 40% chance of mixup\n",
    "                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=0.8)\n",
    "            elif r < 0.8:  # 40% chance of cutmix\n",
    "                inputs, labels_a, labels_b, lam = cutmix_data(inputs, labels, alpha=0.8)\n",
    "            else:  # 20% no augmentation\n",
    "                labels_a, labels_b, lam = labels, labels, 1.0\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            deit_optimizer.zero_grad()\n",
    "            \n",
    "            # Mixed precision forward pass\n",
    "            with autocast():\n",
    "                outputs = deit_model(inputs)\n",
    "                # Use distillation loss\n",
    "                if lam != 1.0:\n",
    "                    # For mixed samples, use base criterion with mixup\n",
    "                    loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    # For regular samples, use distillation loss\n",
    "                    loss = distillation_loss(inputs, outputs, labels)\n",
    "            \n",
    "            # Backward and optimize with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(deit_optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate epoch loss\n",
    "        epoch_loss = train_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        deit_model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = deit_model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Epoch {epoch+1}/100, DeiT Loss: {epoch_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        # Update learning rate\n",
    "        deit_scheduler.step()\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_deit_acc:\n",
    "            best_deit_acc = val_acc\n",
    "            best_deit_model = deit_model.state_dict().copy()\n",
    "            deit_patience_counter = 0\n",
    "        else:\n",
    "            deit_patience_counter += 1\n",
    "            if deit_patience_counter >= patience:\n",
    "                print(f\"Early stopping DeiT training at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"Best DeiT validation accuracy: {best_deit_acc:.4f}\")\n",
    "    \n",
    "    # Save the best DeiT model\n",
    "    torch.save(best_deit_model, \"best_deit_model.pth\")\n",
    "    \n",
    "    # 13. Pseudo-labeling to leverage unlabeled data\n",
    "    print(\"Starting pseudo-labeling...\")\n",
    "    \n",
    "    # Load the best ResNet model for pseudo-labeling\n",
    "    resnet_model.load_state_dict(best_resnet_model)\n",
    "    resnet_model.eval()\n",
    "    \n",
    "    # Assuming there's a directory with unlabeled images\n",
    "    unlabeled_dir = os.path.join(data_dir, 'unlabeled')\n",
    "    if os.path.exists(unlabeled_dir):\n",
    "        unlabeled_paths = [os.path.join(unlabeled_dir, f) for f in os.listdir(unlabeled_dir) \n",
    "                           if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        \n",
    "        # Get pseudo-labels for unlabeled data\n",
    "        all_paths, all_labels = pseudo_labeling(\n",
    "            labeled_dataset=train_dataset,\n",
    "            unlabeled_paths=unlabeled_paths,\n",
    "            model=resnet_model,\n",
    "            device=device,\n",
    "            confidence_threshold=0.85\n",
    "        )\n",
    "        \n",
    "        # Create new dataset with pseudo-labeled data\n",
    "        combined_dataset = SmallDataset(all_paths, all_labels, transform=train_transform)\n",
    "        \n",
    "        # Re-train models with the extended dataset\n",
    "        # This is a simplified version; you may want to implement a full training loop\n",
    "        print(f\"Re-training with {len(all_paths)} images (original + pseudo-labeled)\")\n",
    "        # ... implement re-training here ...\n",
    "    \n",
    "    # 14. Test-time augmentation\n",
    "    print(\"Evaluating with test-time augmentation...\")\n",
    "    \n",
    "    # Load best models\n",
    "    resnet_model.load_state_dict(best_resnet_model)\n",
    "    deit_model.load_state_dict(best_deit_model)\n",
    "    \n",
    "    # Create TTA wrappers\n",
    "    tta_transforms = get_tta_transforms()\n",
    "    resnet_tta = TTAWrapper(resnet_model, tta_transforms).to(device)\n",
    "    deit_tta = TTAWrapper(deit_model, tta_transforms).to(device)\n",
    "    \n",
    "    # Evaluate with TTA\n",
    "    resnet_tta.eval()\n",
    "    deit_tta.eval()\n",
    "    \n",
    "    resnet_correct = 0\n",
    "    deit_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # ResNet predictions with TTA\n",
    "            resnet_outputs = resnet_tta(inputs)\n",
    "            _, resnet_predicted = torch.max(resnet_outputs, 1)\n",
    "            \n",
    "            # DeiT predictions with TTA\n",
    "            deit_outputs = deit_tta(inputs)\n",
    "            _, deit_predicted = torch.max(deit_outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            resnet_correct += (resnet_predicted == labels).sum().item()\n",
    "            deit_correct += (deit_predicted == labels).sum().item()\n",
    "    \n",
    "    resnet_acc = resnet_correct / total\n",
    "    deit_acc = deit_correct / total\n",
    "    \n",
    "    print(f\"ResNet TTA Accuracy: {resnet_acc:.4f}\")\n",
    "    print(f\"DeiT TTA Accuracy: {deit_acc:.4f}\")\n",
    "    \n",
    "    # 15. Ensemble predictions\n",
    "    print(\"Evaluating ensemble model...\")\n",
    "    \n",
    "    ensemble_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get predictions from both models\n",
    "            resnet_outputs = resnet_tta(inputs)\n",
    "            deit_outputs = deit_tta(inputs)\n",
    "            \n",
    "            # Average the predictions (weighted ensemble)\n",
    "            ensemble_outputs = 0.6 * resnet_outputs + 0.4 * deit_outputs\n",
    "            _, ensemble_predicted = torch.max(ensemble_outputs, 1)\n",
    "            \n",
    "            ensemble_correct += (ensemble_predicted == labels).sum().item()\n",
    "    \n",
    "    ensemble_acc = ensemble_correct / total\n",
    "    print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
    "    \n",
    "    # Return best models and accuracies\n",
    "    return {\n",
    "        'resnet_model': best_resnet_model,\n",
    "        'deit_model': best_deit_model,\n",
    "        'resnet_acc': resnet_acc,\n",
    "        'deit_acc': deit_acc,\n",
    "        'ensemble_acc': ensemble_acc\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    data_dir = \"data\"\n",
    "    num_classes = 3  # Adjust based on your dataset\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    set_seed(42)\n",
    "    \n",
    "    # Run the full pipeline\n",
    "    results = full_training_pipeline(data_dir, num_classes, device)\n",
    "    \n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"ResNet Accuracy: {results['resnet_acc']:.4f}\")\n",
    "    print(f\"DeiT Accuracy: {results['deit_acc']:.4f}\")\n",
    "    print(f\"Ensemble Accuracy: {results['ensemble_acc']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a22150-1627-4048-a679-073162ab6865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
