{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312ac7f-ee06-4534-b5ee-082f12814293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 10:25:32,884 - INFO - Using device: mps\n",
      "2025-03-26 10:25:32,888 - INFO - Found 1525 images in 3 classes\n",
      "2025-03-26 10:25:32,889 - INFO - Class Healthy: 407 images\n",
      "2025-03-26 10:25:32,889 - INFO - Class Monkeypox: 563 images\n",
      "2025-03-26 10:25:32,889 - INFO - Class Other: 555 images\n",
      "2025-03-26 10:25:32,889 - INFO - Caching images for faster training...\n",
      "2025-03-26 10:25:35,116 - INFO - Cached 1525 images\n",
      "2025-03-26 10:25:35,152 - INFO - Class weights: tensor([1.2214, 0.8829, 0.8957])\n",
      "2025-03-26 10:25:35,162 - INFO - Starting fold 1/5\n",
      "2025-03-26 10:25:35,165 - INFO - Found 1525 images in 3 classes\n",
      "2025-03-26 10:25:35,166 - INFO - Class Healthy: 407 images\n",
      "2025-03-26 10:25:35,166 - INFO - Class Monkeypox: 563 images\n",
      "2025-03-26 10:25:35,166 - INFO - Class Other: 555 images\n",
      "2025-03-26 10:25:35,166 - INFO - Caching images for faster training...\n",
      "2025-03-26 10:25:36,131 - INFO - Cached 1525 images\n",
      "2025-03-26 10:25:36,246 - INFO - Found 1525 images in 3 classes\n",
      "2025-03-26 10:25:36,246 - INFO - Class Healthy: 407 images\n",
      "2025-03-26 10:25:36,247 - INFO - Class Monkeypox: 563 images\n",
      "2025-03-26 10:25:36,247 - INFO - Class Other: 555 images\n",
      "2025-03-26 10:25:36,247 - INFO - Caching images for faster training...\n",
      "2025-03-26 10:25:37,224 - INFO - Cached 1525 images\n",
      "/var/folders/9z/8tmzxq_56h74xtczwgzc1y740000gn/T/ipykernel_5716/1600620498.py:577: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_amp else None\n",
      "/Users/mmob/.pyenv/versions/3.9.21/envs/jupyter/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/mmob/.pyenv/versions/3.9.21/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/mmob/.pyenv/versions/3.9.21/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'CustomImageDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.data.auto_augment import rand_augment_transform, auto_augment_transform\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "\n",
    "import sklearn.model_selection as skms\n",
    "from PIL import Image\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"training.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Custom Dataset with caching capability\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, cache_images=False):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        self.cache_images = cache_images\n",
    "        \n",
    "        # Get all class directories\n",
    "        self.class_dirs = [d for d in self.img_dir.iterdir() if d.is_dir()]\n",
    "        self.classes = sorted([d.name for d in self.class_dirs])\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Get all image files\n",
    "        self.img_paths = []\n",
    "        self.targets = []\n",
    "        \n",
    "        # Supported image extensions\n",
    "        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "        \n",
    "        # Iterate through each class directory\n",
    "        for class_dir in self.class_dirs:\n",
    "            class_idx = self.class_to_idx[class_dir.name]\n",
    "            \n",
    "            # Get all images in this class directory\n",
    "            for img_path in class_dir.iterdir():\n",
    "                if img_path.suffix.lower() in valid_extensions:\n",
    "                    self.img_paths.append(img_path)\n",
    "                    self.targets.append(class_idx)\n",
    "        \n",
    "        # Create (path, label) pairs\n",
    "        self.samples = list(zip(self.img_paths, self.targets))\n",
    "        \n",
    "        logger.info(f\"Found {len(self.samples)} images in {len(self.classes)} classes\")\n",
    "        for cls, idx in self.class_to_idx.items():\n",
    "            count = self.targets.count(idx)\n",
    "            logger.info(f\"Class {cls}: {count} images\")\n",
    "        \n",
    "        # Image cache to speed up training\n",
    "        self.image_cache = {}\n",
    "        if self.cache_images:\n",
    "            logger.info(\"Caching images for faster training...\")\n",
    "            for idx in range(len(self.samples)):\n",
    "                self._load_image(idx)\n",
    "            logger.info(f\"Cached {len(self.image_cache)} images\")\n",
    "    \n",
    "    def _load_image(self, idx):\n",
    "        img_path, _ = self.samples[idx]\n",
    "        if self.cache_images and str(img_path) in self.image_cache:\n",
    "            return self.image_cache[str(img_path)]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.cache_images:\n",
    "                self.image_cache[str(img_path)] = image\n",
    "                \n",
    "            return image\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a blank image as fallback\n",
    "            return Image.new('RGB', (224, 224), color='gray')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self._load_image(idx)\n",
    "        label = self.samples[idx][1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Advanced data augmentation pipeline\n",
    "def get_transforms(img_size=224):\n",
    "    # Basic transformations\n",
    "    basic_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Advanced training augmentations\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.6, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        # RandAugment from timm\n",
    "        rand_augment_transform('rand-m9-n3-mstd0.5', {'img_size': img_size}),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.25)\n",
    "    ])\n",
    "    \n",
    "    return train_transform, basic_transform\n",
    "\n",
    "# ResNet-DeiT Hybrid Model\n",
    "class ResNetDeiTHybrid(nn.Module):\n",
    "    def __init__(self, num_classes, resnet_pretrained=True, embed_dim=384, depth=8, \n",
    "                 num_heads=6, dropout=0.2, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. ResNet feature extractor\n",
    "        weights = ResNet18_Weights.DEFAULT if resnet_pretrained else None\n",
    "        resnet = resnet18(weights=weights)\n",
    "        \n",
    "        # Remove the final layer and pooling\n",
    "        self.resnet_features = create_feature_extractor(\n",
    "            resnet, \n",
    "            return_nodes={'layer4': 'features'}\n",
    "        )\n",
    "        \n",
    "        # 2. Feature processing to prepare for transformer\n",
    "        # ResNet18 outputs features with shape [B, 512, 7, 7]\n",
    "        feature_dim = 512\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Conv2d(feature_dim, embed_dim, kernel_size=1),\n",
    "            nn.BatchNorm2d(embed_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # 3. Vision Transformer part (DeiT inspired)\n",
    "        # The number of patches depends on the output size of ResNet\n",
    "        # For ResNet18 with 224x224 input, feature map is 7x7 = 49 patches\n",
    "        self.num_patches = 49  # 7x7 feature map\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim))\n",
    "        \n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dim,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=embed_dim * 4,\n",
    "                dropout=dropout,\n",
    "                activation='gelu',\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=depth\n",
    "        )\n",
    "        \n",
    "        # 4. MLP Head with dropout\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        # Initialize transformer weights\n",
    "        nn.init.normal_(self.cls_token, std=0.02)\n",
    "        nn.init.normal_(self.pos_embedding, std=0.02)\n",
    "        \n",
    "        # Initialize MLP head\n",
    "        for m in self.fc.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # 1. Extract features using ResNet\n",
    "        features = self.resnet_features(x)['features']  # [B, 512, 7, 7]\n",
    "        \n",
    "        # 2. Convert to patch embeddings\n",
    "        patch_embeddings = self.to_patch_embedding(features)  # [B, embed_dim, 7, 7]\n",
    "        patch_embeddings = patch_embeddings.flatten(2).transpose(1, 2)  # [B, 49, embed_dim]\n",
    "        \n",
    "        # 3. Add class token and positional embedding\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat((cls_tokens, patch_embeddings), dim=1)  # [B, 50, embed_dim]\n",
    "        x = x + self.pos_embedding\n",
    "        \n",
    "        # 4. Apply transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 5. Use the class token for classification\n",
    "        x = self.norm(x[:, 0])\n",
    "        \n",
    "        # 6. MLP head\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Knowledge Distillation Loss\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, outputs, labels, teacher_outputs):\n",
    "        # Hard loss - CrossEntropy with true labels\n",
    "        hard_loss = self.ce_loss(outputs, labels)\n",
    "        \n",
    "        # Soft loss - KL Divergence with teacher's predictions\n",
    "        soft_loss = F.kl_div(\n",
    "            F.log_softmax(outputs / self.temperature, dim=1),\n",
    "            F.softmax(teacher_outputs / self.temperature, dim=1),\n",
    "            reduction='batchmean'\n",
    "        ) * (self.temperature ** 2)\n",
    "        \n",
    "        # Combined loss\n",
    "        return (1 - self.alpha) * hard_loss + self.alpha * soft_loss\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, train_loader, optimizer, criterion, device, epoch, \n",
    "                    teacher_model=None, mixup_fn=None, scaler=None, distill_criterion=None):\n",
    "    model.train()\n",
    "    if teacher_model is not None:\n",
    "        teacher_model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Apply mixup if available\n",
    "        if mixup_fn is not None:\n",
    "            inputs, targets_a, targets_b, lam = mixup_fn(inputs, targets)\n",
    "            \n",
    "        # Use automatic mixed precision if available\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if teacher_model is not None:\n",
    "                    with torch.no_grad():\n",
    "                        teacher_outputs = teacher_model(inputs)\n",
    "                    loss = distill_criterion(outputs, targets, teacher_outputs)\n",
    "                elif mixup_fn is not None:\n",
    "                    loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "                else:\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "            # Update with gradient scaling\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Standard update\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if teacher_model is not None:\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "                loss = distill_criterion(outputs, targets, teacher_outputs)\n",
    "            elif mixup_fn is not None:\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy (not accurate with mixup but useful for monitoring)\n",
    "        if mixup_fn is None:\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Print progress\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            acc = 100. * correct / total if mixup_fn is None else -1\n",
    "            logger.info(f'Epoch: {epoch} | Batch: {batch_idx+1}/{len(train_loader)} | '\n",
    "                       f'Loss: {total_loss/(batch_idx+1):.4f} | Acc: {acc:.2f}% | '\n",
    "                       f'Time: {batch_time.avg:.3f}s/batch')\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss, acc\n",
    "\n",
    "# Utility class for measurement\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# Progressive unfreezing - helper function\n",
    "def unfreeze_model_parts(model, epoch, total_epochs, layers_to_unfreeze):\n",
    "    if epoch in layers_to_unfreeze:\n",
    "        layer_to_unfreeze = layers_to_unfreeze[epoch]\n",
    "        logger.info(f\"Unfreezing {layer_to_unfreeze}\")\n",
    "        \n",
    "        if layer_to_unfreeze == 'layer3':\n",
    "            for param in model.resnet_features.layer3.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif layer_to_unfreeze == 'layer2':\n",
    "            for param in model.resnet_features.layer2.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif layer_to_unfreeze == 'layer1':\n",
    "            for param in model.resnet_features.layer1.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif layer_to_unfreeze == 'transformer_last':\n",
    "            # Unfreeze last 2 transformer layers\n",
    "            transformer_layers = list(model.transformer.children())\n",
    "            for layer in transformer_layers[-2:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "        elif layer_to_unfreeze == 'transformer_all':\n",
    "            # Unfreeze all transformer layers\n",
    "            for param in model.transformer.parameters():\n",
    "                param.requires_grad = True\n",
    "        elif layer_to_unfreeze == 'all':\n",
    "            # Unfreeze everything\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "# Main training function with k-fold cross-validation\n",
    "def train_model_with_kfold(\n",
    "    data_dir,\n",
    "    num_classes,\n",
    "    img_size=224,\n",
    "    batch_size=32,\n",
    "    num_epochs=30,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    k_folds=5,\n",
    "    embed_dim=384,\n",
    "    transformer_depth=6,\n",
    "    num_heads=6,\n",
    "    dropout=0.2,\n",
    "    use_mixup=True,\n",
    "    mixup_alpha=0.2,\n",
    "    cutmix_alpha=0.2,\n",
    "    label_smoothing=0.1,\n",
    "    use_amp=True,\n",
    "    use_distillation=False,\n",
    "    distillation_alpha=0.5,\n",
    "    cache_images=True\n",
    "):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Get data transforms\n",
    "    train_transform, val_transform = get_transforms(img_size)\n",
    "    \n",
    "    # Load the full dataset\n",
    "    full_dataset = CustomImageDataset(\n",
    "        img_dir=data_dir,\n",
    "        transform=None,  # We'll apply transforms later\n",
    "        cache_images=cache_images\n",
    "    )\n",
    "    \n",
    "    # Get class weights for imbalanced dataset\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    for _, label in full_dataset.samples:\n",
    "        class_counts[label] += 1\n",
    "    class_weights = torch.FloatTensor(1.0 / class_counts)\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "    logger.info(f\"Class weights: {class_weights}\")\n",
    "    \n",
    "    # Create indices for k-fold split\n",
    "    indices = list(range(len(full_dataset)))\n",
    "    \n",
    "    # Use stratified k-fold to maintain class distribution\n",
    "    labels = [label for _, label in full_dataset.samples]\n",
    "    skf = skms.StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Setup mixup function if needed\n",
    "    mixup_fn = None\n",
    "    if use_mixup:\n",
    "        mixup_fn = Mixup(\n",
    "            mixup_alpha=mixup_alpha,\n",
    "            cutmix_alpha=cutmix_alpha,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "    \n",
    "    # Loss function with label smoothing\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=label_smoothing)\n",
    "    \n",
    "    # Keep track of best models across folds\n",
    "    best_models = []\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    # Train with k-fold cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(indices, labels)):\n",
    "        logger.info(f\"Starting fold {fold+1}/{k_folds}\")\n",
    "        \n",
    "        # Create datasets for this fold\n",
    "        train_subsampler = SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        # Create data loaders with transforms\n",
    "        train_loader = DataLoader(\n",
    "            dataset=CustomImageDataset(\n",
    "                img_dir=data_dir,\n",
    "                transform=train_transform,\n",
    "                cache_images=cache_images\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            sampler=train_subsampler,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            dataset=CustomImageDataset(\n",
    "                img_dir=data_dir,\n",
    "                transform=val_transform,\n",
    "                cache_images=cache_images\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            sampler=val_subsampler,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        model = ResNetDeiTHybrid(\n",
    "            num_classes=num_classes,\n",
    "            resnet_pretrained=True,\n",
    "            embed_dim=embed_dim,\n",
    "            depth=transformer_depth,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Initially freeze most of the network for transfer learning\n",
    "        # Start by only training the classification head and positional embeddings\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Unfreeze specific parts\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        model.cls_token.requires_grad = True\n",
    "        model.pos_embedding.requires_grad = True\n",
    "        \n",
    "        # Define which parts to unfreeze and when\n",
    "        layers_to_unfreeze = {\n",
    "            5: 'transformer_last',  # Unfreeze last transformer layers at epoch 5\n",
    "            10: 'transformer_all',  # Unfreeze all transformer at epoch 10\n",
    "            15: 'layer3',           # Unfreeze layer3 of ResNet at epoch 15\n",
    "            20: 'layer2',           # Unfreeze layer2 of ResNet at epoch 20\n",
    "            25: 'all'               # Unfreeze everything at epoch 25\n",
    "        }\n",
    "        \n",
    "        # Initialize teacher model for knowledge distillation if needed\n",
    "        teacher_model = None\n",
    "        distill_criterion = None\n",
    "        if use_distillation:\n",
    "            # Use a bigger model as teacher (like a pre-trained ViT)\n",
    "            teacher_model = torchvision.models.vit_b_16(weights=\"DEFAULT\")\n",
    "            teacher_model.heads[0] = nn.Linear(teacher_model.heads[0].in_features, num_classes)\n",
    "            teacher_model = teacher_model.to(device)\n",
    "            teacher_model.eval()\n",
    "            \n",
    "            # Distillation loss\n",
    "            distill_criterion = DistillationLoss(alpha=distillation_alpha)\n",
    "        \n",
    "        # Move model to device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Optimizer with weight decay\n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=5,  # Restart every 5 epochs\n",
    "            T_mult=2,  # Double the restart interval after each restart\n",
    "            eta_min=learning_rate / 100  # Min learning rate\n",
    "        )\n",
    "        \n",
    "        # Initialize gradient scaler for mixed precision training\n",
    "        scaler = GradScaler() if use_amp else None\n",
    "        \n",
    "        # Early stopping setup\n",
    "        best_acc = 0\n",
    "        patience = 5\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # Progressively unfreeze layers\n",
    "            unfreeze_model_parts(model, epoch, num_epochs, layers_to_unfreeze)\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_loss = train_one_epoch(\n",
    "                model, train_loader, optimizer, criterion, device, epoch,\n",
    "                teacher_model, mixup_fn, scaler, distill_criterion\n",
    "            )\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Log progress\n",
    "            logger.info(f\"Fold {fold+1} | Epoch {epoch+1}/{num_epochs} | \"\n",
    "                       f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                       f\"Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Check if this is the best model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                logger.info(f\"New best model with accuracy: {best_acc:.2f}%\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            # Check for early stopping\n",
    "            if patience_counter >= patience:\n",
    "                logger.info(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Save best model for this fold\n",
    "        model_save_path = f\"model_fold_{fold+1}_acc_{best_acc:.2f}.pth\"\n",
    "        torch.save(best_model_state, model_save_path)\n",
    "        \n",
    "        # Restore best model and evaluate\n",
    "        model.load_state_dict(best_model_state)\n",
    "        final_val_loss, final_val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        logger.info(f\"Fold {fold+1} final results - Val Loss: {final_val_loss:.4f} | Val Acc: {final_val_acc:.2f}%\")\n",
    "        \n",
    "        best_models.append((model, final_val_acc))\n",
    "        fold_accuracies.append(final_val_acc)\n",
    "    \n",
    "    # Report overall results\n",
    "    mean_acc = sum(fold_accuracies) / len(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    logger.info(f\"K-fold cross-validation results:\")\n",
    "    logger.info(f\"Mean accuracy: {mean_acc:.2f}% ± {std_acc:.2f}%\")\n",
    "    \n",
    "    # Return best model across all folds\n",
    "    best_fold = np.argmax(fold_accuracies)\n",
    "    best_model, best_acc = best_models[best_fold]\n",
    "    logger.info(f\"Best model from fold {best_fold+1} with accuracy: {best_acc:.2f}%\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Inference function for the trained model\n",
    "def predict_with_model(model, image_path, transform, device):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = outputs.max(1)\n",
    "    \n",
    "    return predicted.item()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    config = {\n",
    "        \"data_dir\": \"data\",  # Update with your dataset path\n",
    "        \"num_classes\": 3,  # Update with your number of classes\n",
    "        \"img_size\": 224,\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 30,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"k_folds\": 5,\n",
    "        \"embed_dim\": 384,\n",
    "        \"transformer_depth\": 6,\n",
    "        \"num_heads\": 6,\n",
    "        \"dropout\": 0.2,\n",
    "        \"use_mixup\": True,\n",
    "        \"mixup_alpha\": 0.2,\n",
    "        \"cutmix_alpha\": 0.2,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"use_amp\": True,\n",
    "        \"use_distillation\": True,\n",
    "        \"distillation_alpha\": 0.5,\n",
    "        \"cache_images\": True\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    best_model = train_model_with_kfold(**config)\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(best_model.state_dict(), \"best_resnet_deit_hybrid_model.pth\")\n",
    "    \n",
    "    logger.info(\"Training completed and best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2631c-6f9d-4aa0-a5fb-6d08432ad93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
